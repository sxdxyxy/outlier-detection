
@inproceedings{ramaswamy_efficient_2000,
  address = {New York, NY, USA},
  series = {SIGMOD '00},
  title = {Efficient {{Algorithms}} for {{Mining Outliers}} from {{Large Data Sets}}},
  isbn = {978-1-58113-217-5},
  doi = {10.1145/342009.335437},
  abstract = {In this paper, we propose a novel formulation for distance-based outliers that is based on the distance of a point from its kth nearest neighbor. We rank each point on the basis of its distance to its kth nearest neighbor and declare the top n points in this ranking to be outliers. In addition to developing relatively straightforward solutions to finding such outliers based on the classical nested-loop join and index join algorithms, we develop a highly efficient partition-based algorithm for mining outliers. This algorithm first partitions the input data set into disjoint subsets, and then prunes entire partitions as soon as it is determined that they cannot contain outliers. This results in substantial savings in computation. We present the results of an extensive experimental study on real-life and synthetic data sets. The results from a real-life NBA database highlight and reveal several expected and unexpected aspects of the database. The results from a study on synthetic data sets demonstrate that the partition-based algorithm scales well with respect to both data set size and data set dimensionality.},
  timestamp = {2016-06-10T16:27:36Z},
  urldate = {2016-06-08},
  booktitle = {Proceedings of the 2000 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  publisher = {{ACM}},
  author = {Ramaswamy, Sridhar and Rastogi, Rajeev and Shim, Kyuseok},
  year = {2000},
  pages = {427--438},
  file = {Efficient Algorithms for Mining Outliers from Large Data Sets.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Efficient Algorithms for Mining Outliers from Large Data Sets.pdf:application/pdf}
}

@article{hodge_survey_2004,
  title = {A {{Survey}} of {{Outlier Detection Methodologies}}},
  volume = {22},
  issn = {0269-2821, 1573-7462},
  doi = {10.1007/s10462-004-4304-y},
  abstract = {Outlier detection has been used for centuries to detect and, where appropriate, remove anomalous observations from data. Outliers arise due to mechanical faults, changes in system behaviour, fraudulent behaviour, human error, instrument error or simply through natural deviations in populations. Their detection can identify system faults and fraud before they escalate with potentially catastrophic consequences. It can identify errors and remove their contaminating effect on the data set and as such to purify the data for processing. The original outlier detection methods were arbitrary but now, principled and systematic techniques are used, drawn from the full gamut of Computer Science and Statistics. In this paper, we introduce a survey of contemporary techniques for outlier detection. We identify their respective motivations and distinguish their advantages and disadvantages in a comparative review.},
  language = {en},
  timestamp = {2016-06-08T10:52:31Z},
  number = {2},
  urldate = {2016-06-08},
  journal = {Artif Intell Rev},
  author = {Hodge, Victoria J. and Austin, Jim},
  month = oct,
  year = {2004},
  keywords = {Added mass approach,anomaly,Artificial Intelligence (incl. Robotics),Computer Science; general,detection,deviation,noise,Nonlinear Dynamics; Complex Systems; Chaos; Neural Networks,novelty,outlier,recognition},
  pages = {85--126},
  file = {A Survey of Outlier Detection Methodologies.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/A Survey of Outlier Detection Methodologies.pdf:application/pdf}
}

@article{heflin_introduction_2007,
  title = {An {{Introduction}} to the {{OWL Web Ontology Language}}},
  timestamp = {2016-07-14T14:08:02Z},
  urldate = {2016-07-14},
  journal = {Lehigh University. National Science Foundation (NSF)},
  author = {Heflin, Jeff and {others}},
  year = {2007},
  file = {An Introduction to the OWL Web Ontology Language.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/An Introduction to the OWL Web Ontology Language.pdf:application/pdf}
}

@article{ivan_tomek_experiment_1976,
  title = {An {{Experiment}} with the {{Edited Nearest}}-{{Neighbor Rule}}},
  volume = {SMC-6},
  issn = {0018-9472},
  doi = {10.1109/TSMC.1976.4309523},
  abstract = {A number of computer simulation experiments with the
nearest-neighbor classification rule are described. They include classi-
fication by the usual k-NN rule, classification with k-NN on a design
set edited once according to Wilson and classification with k-NN on a,design set edited unlimited number of times by two methods described
in the text. Results of experiments indicate that editing improves per-
formance of the rule. This is not proved rigorously, but a possible ap-
proach to a proof is outlined.},
  timestamp = {2016-06-08T11:01:08Z},
  number = {6},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  author = {{IVAN TOMEK}},
  month = jun,
  year = {1976},
  keywords = {Computer science,Computer simulation,Density functional theory,NASA,Nearest neighbor searches,Physics,Prototypes,Sampling methods,statistical analysis,Testing},
  pages = {448--452},
  file = {An Experiment with the Edited Nearest-Neighbor Rule.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/An Experiment with the Edited Nearest-Neighbor Rule.pdf:application/pdf}
}

@incollection{hutchison_outlier_2009,
  address = {Berlin, Heidelberg},
  title = {Outlier {{Detection}} in {{Axis}}-{{Parallel Subspaces}} of {{High Dimensional Data}}},
  volume = {5476},
  isbn = {978-3-642-01306-5 978-3-642-01307-2},
  timestamp = {2016-06-03T03:56:02Z},
  urldate = {2016-06-03},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Data Mining}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Kriegel, Hans-Peter and Kr{\"o}ger, Peer and Schubert, Erich and Zimek, Arthur},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and {Pandu Rangan}, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Theeramunkong, Thanaruk and Kijsirikul, Boonserm and Cercone, Nick and Ho, Tu-Bao},
  year = {2009},
  pages = {831--838}
}

@book{rosen_discrete_2012,
  address = {New York},
  edition = {7th ed},
  title = {Discrete Mathematics and Its Applications},
  isbn = {978-0-07-338309-5},
  lccn = {QA39.3 .R67 2012},
  timestamp = {2016-06-22T07:24:45Z},
  publisher = {{McGraw-Hill}},
  author = {Rosen, Kenneth H.},
  year = {2012},
  keywords = {Computer science,Mathematics},
  annote = {Includes indexes}
}

@inproceedings{tibaduiza_burgos_principal_2013,
  title = {Principal Component {{Analysis}} vs. {{Independent}} Component Analysis for Damage Detection},
  timestamp = {2016-07-09T03:46:08Z},
  urldate = {2016-07-09},
  booktitle = {Proceedings 6th {{European Workshop}} on {{Structural Health Monitoring}}},
  author = {{Tibaduiza Burgos}, Diego Alexander and {Mujica Delgado}, Luis Eduardo and Anaya, Maribel and {Rodellar Bened{\'e}}, Jos{\'e} and {G{\"u}emes Gordo}, Alfredo},
  year = {2013},
  file = {Principal component Analysis vs. Independent component analysis for damage detection.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Principal component Analysis vs. Independent component analysis for damage detection.pdf:application/pdf}
}

@article{scholkopf_estimating_2001,
  title = {Estimating the {{Support}} of a {{High}}-{{Dimensional Distribution}}},
  volume = {13},
  issn = {0899-7667},
  doi = {10.1162/089976601750264965},
  abstract = {Suppose you are given some data set drawn from an underlying probability distribution P and you want to estimate a ``simple'' subset S of input space such that the probability that a test point drawn from P lies outside of S equals some a priori specified value between 0 and 1.},
  timestamp = {2016-06-08T10:55:06Z},
  number = {7},
  urldate = {2016-06-08},
  journal = {Neural Computation},
  author = {Sch{\"o}lkopf, Bernhard and Platt, John C. and Shawe-Taylor, John and Smola, Alex J. and Williamson, Robert C.},
  year = {七月 1, 2001},
  pages = {1443--1471},
  file = {Estimating the Support of a High-Dimensional Distribution.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Estimating the Support of a High-Dimensional Distribution.pdf:application/pdf}
}

@article{schubert_local_2014,
  title = {Local Outlier Detection Reconsidered: A Generalized View on Locality with Applications to Spatial, Video, and Network Outlier Detection},
  volume = {28},
  issn = {1384-5810, 1573-756X},
  shorttitle = {Local Outlier Detection Reconsidered},
  doi = {10.1007/s10618-012-0300-z},
  language = {en},
  timestamp = {2016-06-10T16:27:33Z},
  number = {1},
  urldate = {2016-06-03},
  journal = {Data Mining and Knowledge Discovery},
  author = {Schubert, Erich and Zimek, Arthur and Kriegel, Hans-Peter},
  month = jan,
  year = {2014},
  keywords = {Artificial Intelligence (incl. Robotics),Data Mining and Knowledge Discovery,Information Storage and Retrieval,Local outlier,Network outlier,Spatial outlier,Statistics for Engineering; Physics; Computer Science; Chemistry and Earth Sciences,Video outlier},
  pages = {190--237},
  file = {Local outlier detection reconsidered - a generalized view on locality with applications to spatial, video, and network outlier detection.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Local outlier detection reconsidered - a generalized view on locality with applications to spatial, video, and network outlier detection.pdf:application/pdf}
}

@inproceedings{zimek_data_2014,
  title = {Data Perturbation for Outlier Detection Ensembles},
  isbn = {978-1-4503-2722-0},
  doi = {10.1145/2618243.2618257},
  language = {en},
  timestamp = {2016-06-03T04:12:55Z},
  urldate = {2016-06-03},
  publisher = {{ACM Press}},
  author = {Zimek, Arthur and Campello, Ricardo J. G. B. and Sander, J{\"o}rg},
  year = {2014},
  keywords = {ensemble,outlier detection},
  pages = {1--12},
  file = {Data Perturbation for Outlier Detection Ensembles.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Data Perturbation for Outlier Detection Ensembles.pdf:application/pdf}
}

@incollection{schubert_evaluation_2012,
  series = {Proceedings},
  title = {On {{Evaluation}} of {{Outlier Rankings}} and {{Outlier Scores}}},
  isbn = {978-1-61197-232-0},
  abstract = {Outlier detection research is currently focusing on the development of new methods and on improving the computation time for these methods. Evaluation however is rather heuristic, often considering just precision in the top k results or using the area under the ROC curve. These evaluation procedures do not allow for assessment of similarity between methods. Judging the similarity of or correlation between two rankings of outlier scores is an important question in itself but it is also an essential step towards meaningfully building outlier detection ensembles, where this aspect has been completely ignored so far. In this study, our generalized view of evaluation methods allows both to evaluate the performance of existing methods as well as to compare different methods w.r.t. their detection performance. Our new evaluation framework takes into consideration the class imbalance problem and offers new insights on similarity and redundancy of existing outlier detection methods. As a result, the design of effective ensemble methods for outlier detection is considerably enhanced.},
  timestamp = {2016-06-08T10:55:01Z},
  urldate = {2016-06-08},
  booktitle = {Proceedings of the 2012 {{SIAM International Conference}} on {{Data Mining}}},
  publisher = {{Society for Industrial and Applied Mathematics}},
  author = {Schubert, E. and Wojdanowski, R. and Zimek, A. and Kriegel, H.},
  year = {四月 26, 2012},
  pages = {1047--1058},
  file = {On Evaluation of Outlier Rankings and Outlier Scores.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/On Evaluation of Outlier Rankings and Outlier Scores.pdf:application/pdf}
}

@article{knorr_distance-based_2000,
  title = {Distance-Based Outliers: Algorithms and Applications},
  volume = {8},
  issn = {1066-8888, 0949-877X},
  shorttitle = {Distance-Based Outliers},
  doi = {10.1007/s007780050006},
  abstract = {. This paper deals with finding outliers (exceptions) in large, multidimensional datasets. The identification of outliers can lead to the discovery of truly unexpected knowledge in areas such as electronic commerce, credit card fraud, and even the analysis of performance statistics of professional athletes. Existing methods that we have seen for finding outliers can only deal efficiently with two dimensions/attributes of a dataset. In this paper, we study the notion of DB (distance-based) outliers. Specifically, we show that (i) outlier detection can be done efficiently for large datasets, and for k-dimensional datasets with large values of k (e.g., k$\geq$5k$\geq$5k $\backslash$ge 5); and (ii), outlier detection is a meaningful and important knowledge discovery task. First, we present two simple algorithms, both having a complexity of O(kN2)O(kN2)O(k $\backslash$: N\^2), k being the dimensionality and N being the number of objects in the dataset. These algorithms readily support datasets with many more than two attributes. Second, we present an optimized cell-based algorithm that has a complexity that is linear with respect to N, but exponential with respect to k. We provide experimental results indicating that this algorithm significantly outperforms the two simple algorithms for k$\leq$4k$\leq$4k $\backslash$leq 4. Third, for datasets that are mainly disk-resident, we present another version of the cell-based algorithm that guarantees at most three passes over a dataset. Again, experimental results show that this algorithm is by far the best for k$\leq$4k$\leq$4k $\backslash$leq 4. Finally, we discuss our work on three real-life applications, including one on spatio-temporal data (e.g., a video surveillance application), in order to confirm the relevance and broad applicability of DB outliers.},
  language = {en},
  timestamp = {2016-06-10T16:27:48Z},
  number = {3-4},
  urldate = {2016-06-08},
  journal = {The VLDB Journal},
  author = {Knorr, Edwin M. and Ng, Raymond T. and Tucakov, Vladimir},
  month = feb,
  year = {2000},
  keywords = {Key words:Outliers/exceptions – Data mining – Data mining applications – Algorithms},
  pages = {237--253},
  file = {Distance-based outliers - algorithms and applications.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Distance-based outliers - algorithms and applications.pdf:application/pdf}
}

@misc{_bayes_2016,
  title = {Bayes' Theorem},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {In probability theory and statistics, Bayes' theorem (alternatively Bayes' law or Bayes' rule) describes the probability of an event, based on conditions that might be related to the event. For example, suppose one is interested in whether a person has cancer, and knows the person's age. If cancer is related to age, then, using Bayes' theorem, information about the person's age can be used to more accurately assess the probability that they have cancer.
When applied, the probabilities involved in Bayes' theorem may have different probability interpretations. In one of these interpretations, the theorem is used directly as part of a particular approach to statistical inference. With the Bayesian probability interpretation the theorem expresses how a subjective degree of belief should rationally change to account for evidence: this is Bayesian inference, which is fundamental to Bayesian statistics. However, Bayes' theorem has applications in a wide range of calculations involving probabilities, not just in Bayesian inference.
Bayes' theorem is named after Rev. Thomas Bayes (/$\Elzverts$beɪz/; 1701\textendash{}1761), who first provided an equation that allows new evidence to update beliefs. It was further developed by Pierre-Simon Laplace, who first published the modern formulation in his 1812 Th{\'e}orie analytique des probabilit{\'e}s. Sir Harold Jeffreys put Bayes' algorithm and Laplace's formulation on an axiomatic basis. Jeffreys wrote that Bayes' theorem "is to the theory of probability what the Pythagorean theorem is to geometry".},
  language = {en},
  timestamp = {2016-06-22T06:52:50Z},
  urldate = {2016-06-22},
  journal = {Wikipedia, the free encyclopedia},
  month = jun,
  year = {2016},
  note = {Page Version ID: 726355062}
}

@incollection{hutchison_mining_2010,
  address = {Berlin, Heidelberg},
  title = {Mining {{Outliers}} with {{Ensemble}} of {{Heterogeneous Detectors}} on {{Random Subspaces}}},
  volume = {5981},
  isbn = {978-3-642-12025-1 978-3-642-12026-8},
  timestamp = {2016-06-03T03:56:02Z},
  urldate = {2016-06-03},
  booktitle = {Database {{Systems}} for {{Advanced Applications}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Nguyen, Hoang Vu and Ang, Hock Hee and Gopalkrishnan, Vivekanand},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and {Pandu Rangan}, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Kitagawa, Hiroyuki and Ishikawa, Yoshiharu and Li, Qing and Watanabe, Chiemi},
  year = {2010},
  pages = {368--383},
  file = {Mining Outliers with Ensemble of Heterogeneous Detectors on Random Subspaces.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Mining Outliers with Ensemble of Heterogeneous Detectors on Random Subspaces.pdf:application/pdf}
}

@article{__2015,
  title = {{半监督学习方法}},
  issn = {0254-4164},
  lccn = {11-1826/TP},
  abstract = {半监督学习研究如何同时利用有类标签的样本和无类标签的样例改进学习性能,成为近年来机器学习领域的研究热点.鉴于半监督学习的理论意义和实际应用价值,系统综述了半监督学习方法.首先概述了半监督学习的相关概念,包括半监督学习的定义、半监督学习研究的发展历程、半监督学习方法依赖的假设以及半监督学习的分类,然后分别从分类、回归、聚类和降维这4个方面详述了半监督学习方法,接着从理论上对半监督学习进行了分析并给出半监督学习的误差界和样本复杂度,最后探讨了半监督学习领域未来的研究方向.},
  language = {中文;},
  timestamp = {2016-07-02T14:48:46Z},
  number = {08},
  urldate = {2016-07-02},
  journal = {计算机学报},
  author = {刘, 建伟 and 刘, 媛 and 罗, 雄麟},
  year = {2015},
  keywords = {label,labeled examples,pair-wise constraints,semi-supervised learning,unlabeled instances,半监督学习,成对约束,无类标签的样例,有类标签的样本,类标签},
  pages = {1592--1617},
  file = {半监督学习方法.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/半监督学习方法.pdf:application/pdf}
}

@book{battiti_lion_2014,
  address = {S.l.},
  edition = {1. ed},
  title = {The {{LION}} Way Machine Learning plus Intelligent Optimization},
  isbn = {978-1-4960-3402-1},
  shorttitle = {The {{LION}} Way},
  language = {eng},
  timestamp = {2016-07-03T03:05:57Z},
  publisher = {{CreateSpace}},
  author = {Battiti, Roberto and Brunato, Mauro},
  year = {2014},
  note = {OCLC: 935407928},
  file = {The LION way machine learning plus intelligent optimization.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/The LION way machine learning plus intelligent optimization.pdf:application/pdf}
}

@misc{_anomaly_2016,
  title = {Anomaly Detection},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {In data mining, anomaly detection (also outlier detection) is the identification of items, events or observations which do not conform to an expected pattern or other items in a dataset. Typically the anomalous items will translate to some kind of problem such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are also referred to as outliers, novelties, noise, deviations and exceptions.
In particular in the context of abuse and network intrusion detection, the interesting objects are often not rare objects, but unexpected bursts in activity. This pattern does not adhere to the common statistical definition of an outlier as a rare object, and many outlier detection methods (in particular unsupervised methods) will fail on such data, unless it has been aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro clusters formed by these patterns.
Three broad categories of anomaly detection techniques exist. Unsupervised anomaly detection techniques detect anomalies in an unlabeled test data set under the assumption that the majority of the instances in the data set are normal by looking for instances that seem to fit least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labeled as "normal" and "abnormal" and involves training a classifier (the key difference to many other statistical classification problems is the inherent unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behavior from a given normal training data set, and then testing the likelihood of a test instance to be generated by the learnt model.},
  language = {en},
  timestamp = {2016-06-03T11:53:49Z},
  urldate = {2016-06-03},
  journal = {Wikipedia, the free encyclopedia},
  month = jun,
  year = {2016},
  note = {Page Version ID: 723343252}
}

@book{james_introduction_2013,
  title = {An Introduction to Statistical Learning},
  volume = {112},
  timestamp = {2016-06-03T11:06:30Z},
  publisher = {{Springer}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  year = {2013},
  keywords = {Added mass approach,重要文献},
  file = {An introduction to statistical learning.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/Machine Learning/An introduction to statistical learning.pdf:application/pdf}
}

@inproceedings{teng_adaptive_1990,
  title = {Adaptive Real-Time Anomaly Detection Using Inductively Generated Sequential Patterns},
  doi = {10.1109/RISP.1990.63857},
  abstract = {A time-based inductive learning approach to the problem of real-time anomaly detection is described. This approach uses sequential rules that characterize a user's behavior over time. A rulebase is used to store patterns of user activities, and anomalies are reported whenever a user's activity deviates significantly from those specified in the rules. The rules in the rulebase characterize either the sequential relationships between security audit records or the temporal properties of the records. The rules are created in two ways: they are either dynamically generated and modified by a time-based inductive engine in order to adapt to changes in a user's behavior, or they are specified by the security management to implement a site security policy. This approach allows the correlation between adjacent security events to be exploited for the purpose of greater sensitivity in anomaly detection against seemingly intractable (or erratic) activities using statistical approaches. Real-time detection of anomaly activities is possible},
  timestamp = {2016-06-08T10:54:36Z},
  booktitle = {, 1990 {{IEEE Computer Society Symposium}} on {{Research}} in {{Security}} and {{Privacy}}, 1990. {{Proceedings}}},
  author = {Teng, H. S. and Chen, K. and Lu, S. C.},
  year = {五月 1990},
  keywords = {adaptive real-time anomaly detection,Computer security,Data security,Engines,inductively generated sequential patterns,Industrial engineering,Information security,Intelligent systems,knowledge engineering,Laboratories,real-time detection,Real time systems,Real-time systems,security of data,sequential rules,Systems engineering and theory,temporal properties,time-based inductive engine},
  pages = {278--284},
  file = {Adaptive real-time anomaly detection using inductively generated sequential patterns.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Adaptive real-time anomaly detection using inductively generated sequential patterns.pdf:application/pdf}
}

@article{campello_hierarchical_2015,
  title = {Hierarchical {{Density Estimates}} for {{Data Clustering}}, {{Visualization}}, and {{Outlier Detection}}},
  volume = {10},
  issn = {15564681},
  doi = {10.1145/2733381},
  language = {en},
  timestamp = {2016-06-03T04:12:46Z},
  number = {1},
  urldate = {2016-06-03},
  journal = {ACM Transactions on Knowledge Discovery from Data},
  author = {Campello, Ricardo J. G. B. and Moulavi, Davoud and Zimek, Arthur and Sander, J{\"o}rg},
  month = jul,
  year = {2015},
  keywords = {data visualization,Density-based clustering,global/local outliers,hierarchical and nonhierarchical clustering,outlier detection,unsupervised and semisupervised clustering},
  pages = {1--51},
  file = {Hierarchical Density Estimates for Data Clustering, Visualization, and Outlier Detection.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Hierarchical Density Estimates for Data Clustering, Visualization, and Outlier Detection.pdf:application/pdf}
}

@article{he_discovering_2003,
  title = {Discovering Cluster-Based Local Outliers},
  volume = {24},
  issn = {0167-8655},
  doi = {10.1016/S0167-8655(03)00003-5},
  abstract = {In this paper, we present a new definition for outlier: cluster-based local outlier, which is meaningful and provides importance to the local data behavior. A measure for identifying the physical significance of an outlier is designed, which is called cluster-based local outlier factor (CBLOF). We also propose the FindCBLOF algorithm for discovering outliers. The experimental results show that our approach outperformed the existing methods on identifying meaningful and interesting outliers.},
  timestamp = {2016-06-08T10:51:40Z},
  number = {9\textendash{}10},
  urldate = {2016-06-08},
  journal = {Pattern Recognition Letters},
  author = {He, Zengyou and Xu, Xiaofei and Deng, Shengchun},
  year = {六月 2003},
  keywords = {Clustering,Data mining,outlier detection},
  pages = {1641--1650},
  file = {Discovering cluster-based local outliers.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Discovering cluster-based local outliers.pdf:application/pdf}
}

@inproceedings{smith_improving_2011,
  title = {Improving Classification Accuracy by Identifying and Removing Instances that Should Be Misclassified},
  doi = {10.1109/IJCNN.2011.6033571},
  abstract = {Appropriately handling noise and outliers is an important issue in data mining. In this paper we examine how noise and outliers are handled by learning algorithms. We introduce a filtering method called PRISM that identifies and removes instances that should be misclassified. We refer to the set of removed instances as ISMs (instances that should be misclassified). We examine PRISM and compare it against 3 existing outlier detection methods and 1 noise reduction technique on 48 data sets using 9 learning algorithms. Using PRISM, the classification accuracy increases from 78.5\% to 79.8\% on a set of 53 data sets and is statistically significant. In addition, the accuracy on the non-outlier instances increases from 82.8\% to 84.7\%. PRISM achieves a higher classification accuracy than the outlier detection methods and compares favorably with the noise reduction method.},
  timestamp = {2016-06-08T10:54:44Z},
  booktitle = {The 2011 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Smith, M. R. and Martinez, T.},
  month = jul,
  year = {2011},
  keywords = {Accuracy,Classification algorithms,data classification accuracy improvement,Data mining,filtering theory,learning algorithm,learning (artificial intelligence),misclassified instance identification,misclassified instance removal,noise,noise handling,Noise reduction,noise reduction technique,outlier handling,pattern classification,Prediction algorithms,PRISM filtering method,Support vector machines,Training},
  pages = {2690--2697},
  file = {Improving classification accuracy by identifying and removing instances that should be misclassified.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Improving classification accuracy by identifying and removing instances that should be misclassified.pdf:application/pdf}
}

@article{zimek_ensembles_2014,
  title = {Ensembles for Unsupervised Outlier Detection: Challenges and Research Questions a Position Paper},
  volume = {15},
  issn = {19310145},
  shorttitle = {Ensembles for Unsupervised Outlier Detection},
  doi = {10.1145/2594473.2594476},
  language = {en},
  timestamp = {2016-06-03T04:12:52Z},
  number = {1},
  urldate = {2016-06-03},
  journal = {ACM SIGKDD Explorations Newsletter},
  author = {Zimek, Arthur and Campello, Ricardo J.G.B. and Sander, J{\"o}rg},
  month = mar,
  year = {2014},
  pages = {11--22},
  file = {Ensembles for Unsupervised Outlier Detection - Challenges and Research Questions a Position Paper.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Ensembles for Unsupervised Outlier Detection - Challenges and Research Questions a Position Paper.pdf:application/pdf}
}

@article{bishop_novelty_1994,
  title = {Novelty Detection and Neural Network Validation},
  volume = {141},
  issn = {1350245X},
  doi = {10.1049/ip-vis:19941330},
  language = {en},
  timestamp = {2016-06-10T16:19:19Z},
  number = {4},
  urldate = {2016-06-10},
  journal = {IEE Proceedings - Vision, Image, and Signal Processing},
  author = {Bishop, C.M.},
  year = {1994},
  pages = {217}
}

@incollection{hawkins_outlier_2002,
  series = {Lecture Notes in Computer Science},
  title = {Outlier {{Detection Using Replicator Neural Networks}}},
  copyright = {\textcopyright{}2002 Springer-Verlag Berlin Heidelberg},
  isbn = {978-3-540-44123-6 978-3-540-46145-6},
  abstract = {We consider the problem of finding outliers in large multivariate databases. Outlier detection can be applied during the data cleansing process of data mining to identify problems with the data itself, and to fraud detection where groups of outliers are often of particular interest. We use replicator neural networks (RNNs) to provide a measure of the outlyingness of data records. The performance of the RNNs is assessed using a ranked score measure. The effectiveness of the RNNs for outlier detection is demonstrated on two publicly available databases.},
  language = {en},
  timestamp = {2016-06-08T10:51:02Z},
  number = {2454},
  urldate = {2016-06-08},
  booktitle = {Data {{Warehousing}} and {{Knowledge Discovery}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Hawkins, Simon and He, Hongxing and Williams, Graham and Baxter, Rohan},
  editor = {Kambayashi, Yahiko and Winiwarter, Werner and Arikawa, Masatoshi},
  month = sep,
  year = {2002},
  keywords = {Computer Communication Networks,Database management,Data Structures; Cryptology and Information Theory,Information Storage and Retrieval,Information Systems Applications (incl. Internet),Multimedia Information Systems,已读文献,重要文献},
  pages = {170--180},
  file = {Outlier Detection Using Replicator Neural Networks.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Outlier Detection Using Replicator Neural Networks.pdf:application/pdf},
  doi = {10.1007/3-540-46145-0_17}
}

@misc{_eureqa_2016,
  title = {Eureqa},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {Eureqa is a proprietary A.I.-powered modeling engine originally created by Cornell's Artificial Intelligence Lab and later commercialized by Nutonian, Inc. The software uses evolutionary search to determine mathematical equations that describe sets of data in their simplest form.},
  language = {en},
  timestamp = {2016-06-23T13:01:53Z},
  urldate = {2016-06-23},
  journal = {Wikipedia, the free encyclopedia},
  month = may,
  year = {2016},
  note = {Page Version ID: 721232780}
}

@inproceedings{kriegel_outlier_2012,
  title = {Outlier {{Detection}} in {{Arbitrarily Oriented Subspaces}}},
  doi = {10.1109/ICDM.2012.21},
  abstract = {In this paper, we propose a novel outlier detection model to find outliers that deviate from the generating mechanisms of normal instances by considering combinations of different subsets of attributes, as they occur when there are local correlations in the data set. Our model enables to search for outliers in arbitrarily oriented subspaces of the original feature space. We show how in addition to an outlier score, our model also derives an explanation of the outlierness that is useful in investigating the results. Our experiments suggest that our novel method can find different outliers than existing work and can be seen as a complement of those approaches.},
  timestamp = {2016-06-08T10:25:06Z},
  booktitle = {2012 {{IEEE}} 12th {{International Conference}} on {{Data Mining}}},
  author = {Kriegel, H. P. and Kr{\"o}ger, P. and Schubert, E. and Zimek, A.},
  year = {十二月 2012},
  keywords = {Anomaly detection,arbitrarily oriented subspace,Correlation,Covariance matrix,Data mining,Data models,Eigenvalues and eigenfunctions,Feature extraction,normal instance mechanism,outlier detection,outlier detection model,outlier score,Principal component analysis,statistical analysis,unsupervised learning,Vectors},
  pages = {379--388},
  file = {Outlier Detection in Arbitrarily Oriented Subspaces.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Outlier Detection in Arbitrarily Oriented Subspaces.pdf:application/pdf}
}

@article{schmidhuber_draft-deep_2014,
  title = {Draft-{{Deep Learning}} in {{Neural Networks}}- {{An Overview}}},
  shorttitle = {Draft},
  timestamp = {2016-07-02T16:45:11Z},
  urldate = {2016-07-02},
  author = {Schmidhuber, J{\"u}rgen},
  year = {2014},
  file = {Draft-Deep Learning in Neural Networks- An Overview.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Draft-Deep Learning in Neural Networks- An Overview.pdf:application/pdf}
}

@misc{_outlier_2016,
  title = {Outlier},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {In statistics, an outlier is an observation point that is distant from other observations. An outlier may be due to variability in the measurement or it may indicate experimental error; the latter are sometimes excluded from the data set.
Outliers can occur by chance in any distribution, but they often indicate either measurement error or that the population has a heavy-tailed distribution. In the former case one wishes to discard them or use statistics that are robust to outliers, while in the latter case they indicate that the distribution has high skewness and that one should be very cautious in using tools or intuitions that assume a normal distribution. A frequent cause of outliers is a mixture of two distributions, which may be two distinct sub-populations, or may indicate 'correct trial' versus 'measurement error'; this is modeled by a mixture model.
In most larger samplings of data, some data points will be further away from the sample mean than what is deemed reasonable. This can be due to incidental systematic error or flaws in the theory that generated an assumed family of probability distributions, or it may be that some observations are far from the center of the data. Outlier points can therefore indicate faulty data, erroneous procedures, or areas where a certain theory might not be valid. However, in large samples, a small number of outliers is to be expected (and not due to any anomalous condition).
Outliers, being the most extreme observations, may include the sample maximum or sample minimum, or both, depending on whether they are extremely high or low. However, the sample maximum and minimum are not always outliers because they may not be unusually far from other observations.
Naive interpretation of statistics derived from data sets that include outliers may be misleading. For example, if one is calculating the average temperature of 10 objects in a room, and nine of them are between 20 and 25 degrees Celsius, but an oven is at 175 $^\circ$C, the median of the data will be between 20 and 25 $^\circ$C but the mean temperature will be between 35.5 and 40 $^\circ$C. In this case, the median better reflects the temperature of a randomly sampled object than the mean; naively interpreting the mean as "a typical sample", equivalent to the median, is incorrect. As illustrated in this case, outliers may indicate data points that belong to a different population than the rest of the sample set.
Estimators capable of coping with outliers are said to be robust: the median is a robust statistic of central tendency, while the mean is not.},
  language = {en},
  timestamp = {2016-07-07T07:12:05Z},
  urldate = {2016-07-07},
  journal = {Wikipedia, the free encyclopedia},
  month = jun,
  year = {2016},
  note = {Page Version ID: 727210205},
  keywords = {Added mass approach,重要文献}
}

@article{denning_intrusion-detection_1987,
  title = {An {{Intrusion}}-{{Detection Model}}},
  volume = {SE-13},
  issn = {0098-5589},
  doi = {10.1109/TSE.1987.232894},
  abstract = {A model of a real-time intrusion-detection expert system capable of detecting break-ins, penetrations, and other forms of computer abuse is described. The model is based on the hypothesis that security violations can be detected by monitoring a system's audit records for abnormal patterns of system usage. The model includes profiles for representing the behavior of subjects with respect to objects in terms of metrics and statistical models, and rules for acquiring knowledge about this behavior from audit records and for detecting anomalous behavior. The model is independent of any particular system, application environment, system vulnerability, or type of intrusion, thereby providing a framework for a general-purpose intrusion-detection expert system.},
  timestamp = {2016-06-08T10:42:01Z},
  number = {2},
  journal = {IEEE Transactions on Software Engineering},
  author = {Denning, D. E.},
  year = {二月 1987},
  keywords = {Abnormal behavior,auditing,Computerized monitoring,Contracts,Environmental economics,Expert systems,intrusions,Invasive software,Joining processes,monitoring,object detection,Operating systems,profiles,Real time systems,security,statistical measures},
  pages = {222--232},
  file = {An Intrusion-Detection Model.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/An Intrusion-Detection Model.pdf:application/pdf}
}

@article{zheng_self-adaptive_2016,
  title = {Self-Adaptive Statistical Process Control for Anomaly Detection in Time Series},
  volume = {57},
  issn = {09574174},
  doi = {10.1016/j.eswa.2016.03.029},
  language = {en},
  timestamp = {2016-07-07T13:23:49Z},
  urldate = {2016-06-26},
  journal = {Expert Systems with Applications},
  author = {Zheng, Dequan and Li, Fenghuan and Zhao, Tiejun},
  month = sep,
  year = {2016},
  keywords = {Anomaly detection,Fuzzy set theory,Self-adaptive,Statistical process control,Statistical testing,重要文献},
  pages = {324--336},
  file = {Self-adaptive statistical process control for anomaly detection in time series.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Self-adaptive statistical process control for anomaly detection in time series.pdf:application/pdf}
}

@incollection{goos_fast_2002,
  address = {Berlin, Heidelberg},
  title = {Fast {{Outlier Detection}} in {{High Dimensional Spaces}}},
  volume = {2431},
  isbn = {978-3-540-44037-6 978-3-540-45681-0},
  timestamp = {2016-06-08T17:03:37Z},
  urldate = {2016-06-08},
  booktitle = {Principles of {{Data Mining}} and {{Knowledge Discovery}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Angiulli, Fabrizio and Pizzuti, Clara},
  editor = {Goos, Gerhard and Hartmanis, Juris and {van Leeuwen}, Jan and Carbonell, Jaime G. and Siekmann, J{\"o}rg and Elomaa, Tapio and Mannila, Heikki and Toivonen, Hannu},
  year = {2002},
  keywords = {Artificial Intelligence (incl. Robotics),Database management,Document Preparation and Text Processing,Information Storage and Retrieval,Mathematical Logic and Formal Languages,Probability and Statistics in Computer Science},
  pages = {15--27},
  file = {Fast Outlier Detection in High Dimensional Spaces.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Fast Outlier Detection in High Dimensional Spaces.pdf:application/pdf}
}

@article{lee_integrating_2011,
  title = {Integrating Independent Component Analysis and Local Outlier Factor for Plant-Wide Process Monitoring},
  volume = {21},
  issn = {0959-1524},
  doi = {10.1016/j.jprocont.2011.06.004},
  abstract = {We propose a novel process monitoring method integrating independent component analysis (ICA) and local outlier factor (LOF). LOF is a recently developed outlier detection technique which is a density-based outlierness calculation method. In the proposed monitoring scheme, ICA transformation is performed and the control limit of LOF value is obtained based on the normal operating condition (NOC) dataset. Then, at the monitoring phase, the LOF value of current observation is computed at each monitoring time, which determines whether the current process is a fault or not. The comparison experiments are conducted with existing ICA-based monitoring schemes on widely used benchmark processes, a simple multivariate process and the Tennessee Eastman process. The proposed scheme shows the improved accuracy over existing schemes. By adopting LOF, the monitoring statistic is computed regardless of data distribution. Therefore, the proposed scheme integrating ICA and LOF is more suitable for real industry where the monitoring variables are the mixture of Gaussian and non-Gaussian variables, whereas existing ICA-based schemes assume only non-Gaussian distribution.},
  timestamp = {2016-07-11T13:24:47Z},
  number = {7},
  urldate = {2016-07-11},
  journal = {Journal of Process Control},
  author = {Lee, Jaeshin and Kang, Bokyoung and Kang, Suk-Ho},
  month = aug,
  year = {2011},
  keywords = {Fault detection,Independent component analysis,Local outlier factor,Multivariate statistical process control,Process monitoring,Tennessee Eastman process},
  pages = {1011--1021}
}

@article{dixon_simplified_1960,
  title = {Simplified {{Estimation}} from {{Censored Normal Samples}}},
  volume = {31},
  issn = {0003-4851},
  doi = {10.1214/aoms/1177705900},
  language = {en},
  timestamp = {2016-06-10T16:19:19Z},
  number = {2},
  urldate = {2016-06-10},
  journal = {The Annals of Mathematical Statistics},
  author = {Dixon, W. J.},
  month = jun,
  year = {1960},
  pages = {385--391}
}

@article{chandola_anomaly_2009,
  title = {Anomaly {{Detection}}: {{A Survey}}},
  volume = {41},
  issn = {0360-0300},
  shorttitle = {Anomaly {{Detection}}},
  doi = {10.1145/1541880.1541882},
  abstract = {Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.},
  timestamp = {2016-06-03T03:58:56Z},
  number = {3},
  urldate = {2016-06-03},
  journal = {ACM Comput. Surv.},
  author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
  year = {七月 2009},
  keywords = {Anomaly detection,outlier detection},
  pages = {15:1--15:58},
  file = {Anomaly Detection - A Survey.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Anomaly Detection - A Survey.pdf:application/pdf}
}

@article{moonesinghe_outrank:_2008,
  title = {{{OutRank}}: {{A GRAPH}}-{{BASED OUTLIER DETECTION FRAMEWORK USING RANDOM WALK}}},
  volume = {17},
  issn = {0218-2130},
  shorttitle = {{{OutRank}}},
  doi = {10.1142/S0218213008003753},
  abstract = {This paper introduces a stochastic graph-based algorithm, called OutRank, for detecting outliers in data. We consider two approaches for constructing a graph representation of the data, based on the object similarity and number of shared neighbors between objects. The heart of this approach is the Markov chain model that is built upon this graph, which assigns an outlier score to each object. Using this framework, we show that our algorithm is more robust than the existing outlier detection schemes and can effectively address the inherent problems of such schemes. Empirical studies conducted on both real and synthetic data sets show that significant improvements in detection rate and false alarm rate are achieved using the proposed framework.},
  timestamp = {2016-07-11T13:27:46Z},
  number = {01},
  urldate = {2016-07-11},
  journal = {Int. J. Artif. Intell. Tools},
  author = {Moonesinghe, H. D. K. and Tan, Pang-Ning},
  month = feb,
  year = {2008},
  pages = {19--36},
  file = {OutRank - A GRAPH-BASED OUTLIER DETECTION FRAMEWORK USING RANDOM WALK.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/OutRank - A GRAPH-BASED OUTLIER DETECTION FRAMEWORK USING RANDOM WALK.pdf:application/pdf}
}

@book{soulmachine_machine_2015,
  title = {Machine {{Learning Cheat Sheet}}-{{Classical}} Equations, Diagrams and Tricks in Machine Learning},
  abstract = {This cheat sheet contains many classical equations and diagrams on machine learning, which will help you quickly
recall knowledge and ideas in machine learning.
This cheat sheet has three significant advantages:
1. Strong typed. Compared to programming languages, mathematical formulas are weakly typed. For example, X can
be a set, a random variable, or a matrix. This causes difficulty in understanding the meaning of formulas. In this
cheat sheet, I try my best to standardize symbols used, see section \textsection.
2. More parentheses. In machine learning, authors are prone to omit parentheses, brackets and braces, this usually
causes ambiguity in mathematical formulas. In this cheat sheet, I use parentheses(brackets and braces) at where they are needed, to make formulas easy to understand.
3. Less thinking jumps. In many books, authors are prone to omit some steps that are trivial in his option. But it often
makes readers get lost in the middle way of derivation.},
  timestamp = {2016-07-04T15:03:41Z},
  urldate = {2016-07-04},
  author = {{soulmachine}},
  year = {2015},
  keywords = {Added mass approach,重要文献},
  file = {Machine Learning Cheat Sheet-Classical equations, diagrams and tricks in machine learning.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Machine Learning Cheat Sheet-Classical equations, diagrams and tricks in machine learning.pdf:application/pdf}
}

@article{nurunnabi_outlier_2015,
  title = {Outlier Detection and Robust Normal-Curvature Estimation in Mobile Laser Scanning {{3D}} Point Cloud Data},
  volume = {48},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2014.10.014},
  abstract = {This paper proposes two robust statistical techniques for outlier detection and robust saliency features, such as surface normal and curvature, estimation in laser scanning 3D point cloud data. One is based on a robust z-score and the other uses a Mahalanobis type robust distance. The methods couple the ideas of point to plane orthogonal distance and local surface point consistency to get Maximum Consistency with Minimum Distance (MCMD). The methods estimate the best-fit-plane based on most probable outlier free, and most consistent, points set in a local neighbourhood. Then the normal and curvature from the best-fit-plane will be highly robust to noise and outliers. Experiments are performed to show the performance of the algorithms compared to several existing well-known methods (from computer vision, data mining, machine learning and statistics) using synthetic and real laser scanning datasets of complex (planar and non-planar) objects. Results for plane fitting, denoising, sharp feature preserving and segmentation are significantly improved. The algorithms are demonstrated to be significantly faster, more accurate and robust. Quantitatively, for a sample size of 50 with 20\% outliers the proposed MCMD\_Z is approximately 5, 15 and 98 times faster than the existing methods: uLSIF, RANSAC and RPCA, respectively. The proposed MCMD\_MD method can tolerate 75\% clustered outliers, whereas, RPCA and RANSAC can only tolerate 47\% and 64\% outliers, respectively. In terms of outlier detection, for the same dataset, MCMD\_Z has an accuracy of 99.72\%, 0.4\% false positive rate and 0\% false negative rate; for RPCA, RANSAC and uLSIF, the accuracies are 97.05\%, 47.06\% and 94.54\%, respectively, and they have misclassification rates higher than the proposed methods. The new methods have potential for local surface reconstruction, fitting, and other point cloud processing tasks.},
  timestamp = {2016-07-22T13:41:56Z},
  number = {4},
  urldate = {2016-07-11},
  journal = {Pattern Recognition},
  author = {Nurunnabi, Abdul and West, Geoff and Belton, David},
  month = apr,
  year = {2015},
  keywords = {Added mass approach,Feature extraction,Plane fitting,Point cloud denoising,Robust saliency feature,Segmentation,Surface reconstruction},
  pages = {1404--1419},
  annote = {Highlights
\textbullet{}Two statistical techniques are proposed for outlier detection in point cloud data.\textbullet{}The proposed methods can fit robust plane in laser scanning data.\textbullet{}The proposed methods produce robust normal and curvature in point cloud processing.\textbullet{}They are faster and robust than RANSAC, robust PCA and other existing efficient methods.\textbullet{}They have potential for point cloud denoising, segmentation, and reconstruction.},
  file = {Outlier detection and robust normal-curvature estimation in mobile laser scanning 3D point cloud data.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Outlier detection and robust normal-curvature estimation in mobile laser scanning 3D point cloud data.pdf:application/pdf}
}

@misc{weisstein_outlier_????,
  type = {Text},
  title = {Outlier},
  copyright = {Copyright 1999-2016 Wolfram Research, Inc.  See http://mathworld.wolfram.com/about/terms.html for a full terms of use statement.},
  abstract = {An outlier is an observation that lies outside the overall pattern of a distribution (Moore and McCabe 1999). Usually, the presence of an outlier indicates some sort of problem. This can be a case which does not fit the model under study, or an error in measurement. Outliers are often easy to spot in histograms. For example, the point on the far left in the above figure is an outlier. A convenient definition of a outlier is a point which falls more than 1.5 times the interquartile range...},
  language = {en},
  timestamp = {2016-06-12T04:07:06Z},
  urldate = {2016-06-12},
  howpublished = {\url{http://mathworld.wolfram.com/Outlier.html}},
  author = {Weisstein, Eric W.},
  keywords = {已读文献,重要文献}
}

@article{campos_evaluation_2016,
  title = {On the Evaluation of Unsupervised Outlier Detection: Measures, Datasets, and an Empirical Study},
  volume = {30},
  issn = {1573-756X},
  doi = {10.1007/s10618-015-0444-8},
  abstract = {The evaluation of unsupervised outlier detection algorithms is a constant challenge in data mining research. Little is known regarding the strengths and weaknesses of different standard outlier detection models, and the impact of parameter choices for these algorithms. The scarcity of appropriate benchmark datasets with ground truth annotation is a significant impediment to the evaluation of outlier methods. Even when labeled datasets are available, their suitability for the outlier detection task is typically unknown. Furthermore, the biases of commonly-used evaluation measures are not fully understood. It is thus difficult to ascertain the extent to which newly-proposed outlier detection methods improve over established methods. In this paper, we perform an extensive experimental study on the performance of a representative set of standard k nearest neighborhood-based methods for unsupervised outlier detection, across a wide variety of datasets prepared for this purpose. Based on the overall performance of the outlier detection methods, we provide a characterization of the datasets themselves, and discuss their suitability as outlier detection benchmark sets. We also examine the most commonly-used measures for comparing the performance of different methods, and suggest adaptations that are more suitable for the evaluation of outlier detection results.},
  timestamp = {2016-06-30T13:26:23Z},
  number = {4},
  journal = {Data Mining and Knowledge Discovery},
  author = {Campos, Guilherme O. and Zimek, Arthur and Sander, J{\"o}rg and Campello, Ricardo J. G. B. and Micenkov{\'a}, Barbora and Schubert, Erich and Assent, Ira and Houle, Michael E.},
  year = {2016},
  pages = {891--927},
  file = {On the evaluation of unsupervised outlier detection - measures, datasets, and an empirical study.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/On the evaluation of unsupervised outlier detection - measures, datasets, and an empirical study.pdf:application/pdf}
}

@incollection{liu_interpreting_2011,
  address = {Philadelphia, PA},
  title = {Interpreting and {{Unifying Outlier Scores}}},
  isbn = {978-0-89871-992-5 978-1-61197-281-8},
  language = {en},
  timestamp = {2016-06-03T03:56:02Z},
  urldate = {2016-06-03},
  booktitle = {Proceedings of the 2011 {{SIAM International Conference}} on {{Data Mining}}},
  publisher = {{Society for Industrial and Applied Mathematics}},
  author = {Kriegel, Hans-Peter and Kroger, Peer and Schubert, Erich and Zimek, Arthur},
  editor = {Liu, Bing and Liu, Huan and Clifton, Chris and Washio, Takashi and Kamath, Chandrika},
  month = apr,
  year = {2011},
  pages = {13--24},
  file = {Interpreting and Unifying Outlier Scores.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Interpreting and Unifying Outlier Scores.pdf:application/pdf}
}

@article{zimek_survey_2012,
  title = {A Survey on Unsupervised Outlier Detection in High-Dimensional Numerical Data},
  volume = {5},
  issn = {19321864},
  doi = {10.1002/sam.11161},
  language = {en},
  timestamp = {2016-06-10T16:27:29Z},
  number = {5},
  urldate = {2016-06-03},
  journal = {Statistical Analysis and Data Mining},
  author = {Zimek, Arthur and Schubert, Erich and Kriegel, Hans-Peter},
  month = oct,
  year = {2012},
  keywords = {anomalies in high-dimensional data,approximate outlier detection,correlation outlier detection,curse of dimensionality,outlier detection in high-dimensional data,subspace outlier detection},
  pages = {363--387},
  file = {A survey on unsupervised outlier detection in high-dimensional numerical data.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/A survey on unsupervised outlier detection in high-dimensional numerical data.pdf:application/pdf}
}

@inproceedings{breunig_lof:_2000,
  address = {New York, NY, USA},
  series = {SIGMOD '00},
  title = {{{LOF}}: {{Identifying Density}}-Based {{Local Outliers}}},
  isbn = {978-1-58113-217-5},
  shorttitle = {{{LOF}}},
  doi = {10.1145/342009.335388},
  abstract = {For many KDD applications, such as detecting criminal activities in E-commerce, finding the rare instances or the outliers, can be more interesting than finding the common patterns. Existing work in outlier detection regards being an outlier as a binary property. In this paper, we contend that for many scenarios, it is more meaningful to assign to each object a degree of being an outlier. This degree is called the local outlier factor (LOF) of an object. It is local in that the degree depends on how isolated the object is with respect to the surrounding neighborhood. We give a detailed formal analysis showing that LOF enjoys many desirable properties. Using real-world datasets, we demonstrate that LOF can be used to find outliers which appear to be meaningful, but can otherwise not be identified with existing approaches. Finally, a careful performance evaluation of our algorithm confirms we show that our approach of finding local outliers can be practical.},
  timestamp = {2016-07-01T15:46:40Z},
  urldate = {2016-06-08},
  booktitle = {Proceedings of the 2000 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  publisher = {{ACM}},
  author = {Breunig, Markus M. and Kriegel, Hans-Peter and Ng, Raymond T. and Sander, J{\"o}rg},
  year = {2000},
  keywords = {database mining,outlier detection},
  pages = {93--104},
  file = {LOF - Identifying Density-based Local Outliers.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/LOF - Identifying Density-based Local Outliers.pdf:application/pdf}
}

@article{grubbs_procedures_1969,
  title = {Procedures for {{Detecting Outlying Observations}} in {{Samples}}},
  volume = {11},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.1969.10490657},
  language = {en},
  timestamp = {2016-06-14T00:08:28Z},
  number = {1},
  urldate = {2016-06-10},
  journal = {Technometrics},
  author = {Grubbs, Frank E.},
  month = feb,
  year = {1969},
  pages = {1--21},
  file = {Procedures for Detecting Outlying Observations in Samples.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Procedures for Detecting Outlying Observations in Samples.pdf:application/pdf}
}

@inproceedings{lazarevic_feature_2005,
  title = {Feature Bagging for Outlier Detection},
  isbn = {978-1-59593-135-1},
  doi = {10.1145/1081870.1081891},
  abstract = {Outlier detection has recently become an important problem in many industrial and financial applications. In this paper, a novel feature bagging approach for detecting outliers in very large, high dimensional and noisy databases is proposed. It combines results from multiple outlier detection algorithms that are applied using different set of features. Every outlier detection algorithm uses a small subset of features that are randomly selected from the original feature set. As a result, each outlier detector identifies different outliers, and thus assigns to all data records outlier scores that correspond to their probability of being outliers. The outlier scores computed by the individual outlier detection algorithms are then combined in order to find the better quality outliers. Experiments performed on several synthetic and real life data sets show that the proposed methods for combining outputs from multiple outlier detection algorithms provide non-trivial improvements over the base algorithm.},
  language = {en},
  timestamp = {2016-09-01T03:31:09Z},
  urldate = {2016-06-03},
  publisher = {{ACM Press}},
  author = {Lazarevic, Aleksandar and Kumar, Vipin},
  year = {2005},
  pages = {157},
  file = {Feature bagging for outlier detection.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Feature bagging for outlier detection.pdf:application/pdf}
}

@article{singh_outlier_2012,
  title = {Outlier Detection: Applications and Techniques},
  volume = {9},
  shorttitle = {Outlier Detection},
  timestamp = {2016-07-18T15:04:05Z},
  number = {1},
  urldate = {2016-07-18},
  journal = {International Journal of Computer Science Issues},
  author = {Singh, Karanjit and Upadhyaya, Shuchita},
  year = {2012},
  pages = {307--323},
  file = {Outlier detection - applications and techniques.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Outlier detection - applications and techniques.pdf:application/pdf}
}

@phdthesis{__2008,
  type = {博士},
  title = {{空间离群点挖掘技术的研究}},
  abstract = {空间离群点是与其空间邻域中其它空间对象的非空间属性值存在明显差异的空间对象。空间离群点挖掘是空间数据挖掘的一个重要分支,在交通控制、遥感图像分析、气象预报和人口统计数据分析等应用中可揭示重要现象。
随着传感器设备技术的发展,数据采集设备的数量越来越多,精度越来越高,采集的项目也越来越多,因此数据量越来越大,维数越来越高。然而现有的空间离群点挖掘算法主要是针对单维或中低维的中小规模数据量的挖掘,难以适应高维大数据量的挖掘,并且现有算法没有充分考虑空间数据的特点,挖掘的不是真正意义上的空间离群点,而是全局离群点。算法存在用户依赖性大,检测精度低,挖掘效率低等局限。此外,随着网络技术、传感器技术和无线通信技术的发展,数据的采集、收集、保存和处理都呈现分散状态,因此,基于分布环境的数据挖掘也引起人们的关注,但基于分布环境的空间离群点挖掘算法还未见报道。
本文将根据空间数据自身的特点,研究属性划分方法和属性的权值设置方法,空间离群程度的度量方法,实现挖掘精度高、用户依赖性少的高效的空间离群点挖掘算法。针对现有算法主要局限在数值型属性数据处理上的不足,通过将非数值型数据转化为数值型数据,实现基于混合型属性的统一算法。针对高维大数据量,采用剪枝策略、基于子空间的离群点挖掘和集成学习的方法实现高维大数据量的挖掘:针对分布环境下的空间离群点挖掘,提出了基于隐私保护的空间离群点挖掘算法。论文的主要贡献如下:
(1)提出基于属性划分的方法解决局部离群点的挖掘问题。一般的局部离群点的挖掘采用的是满维属性的挖掘方法,如LOF(Local Outlier Factor)方法,其结果是局部邻域的确定非常耗时,由于所有维属性不加区分地等同看待,所以离群度度量的准确性受到影响,影响了挖掘的精度和速度。提出将数据对象的属性划分为标识属性、环境属性和固有属性,标识属性起着标识对象的作用,如数据对象名称等;环境属性决定了对象所处环境,如地理位置、时间、序列等,可利用环境属性确定邻域;固有属性是数据对象特有属性,包括行为属性和状态属性,决定了对象的行为和状态特征,可利用该类属性确定对象的离群程度。
(2)提出空间数据对象的离群程度的新的度量方法,即基于空间数据特性的空间局部离群系数SLOF(Spatial Local Outlier Factor)的度量方法;提出基于空间离群度的空间离群点挖掘算法ASLOF(Algodthm based on SLOF)。将数据对象的属性分为标识属性、空间属性和非空间属性,利用空间属性确定空间邻域、建立空间索引,利用非空间属性确定对象的离群程度,并在离群度的度量中引入属性的权值,提高度量精度,据此提出了基于空间离群度的空间离群点挖掘算法。理论证明和实验测试结果表明,ASLOF在挖掘的精度、用户依赖性和算法性能上均优于现有算法。
(3)提出混合属性的统一的空间离群度的度量方法和挖掘算法。从离群点性质入手,通过统计分类属性的频度,将分类属性转化为数值型,并通过属性的权值设置和属性的标准化等处理后,实现基于混合属性的空间离群点的统一挖掘算法。实验结果表明,算法可有效实现混合属性的空间离群度的统一度量计算和有效挖掘。
(4)提出基于集成学习的子空间离群点集成的高维大数据量的空间离群点快速挖掘算法S2OEAHL(Subspace Spatial Outlier Ensemble Algorithm baSed High-dimensional Large data sets)。由于很多空间数据对象的标识属性中含有空间对象所在的地域标识,根据地域标识构建对象的层次编码树,基于层次编码树,实现数据的分区和对象的快速检索,通过计算分区的上下界和使用包围盒检测方法,剪除明显不含有离群点的分区,保留可能含有离群点的分区作为候选分区,实现了分区的快速剪枝,从而降低数据处理数量。对候选分区采用子空间挖掘方法,为避免与属性维度成指数关系的大量搜索,采用指定子空间挖掘和基于子空间权值的集成融合方法来解决高维数据的离群点挖掘问题。算法的实现中采用了基于单维子空间的离群系数挖掘方法,并利用优化计算的方法求得被检测对象所对应的各属性的权值,在此基础上通过集成融合函数求得被检测对象的离群度,根据离群度的排序可获得所求离群点。理论证明和实验结果均表明算法的有效性和计算的高效性。
(5)提出基于分布环境的隐私保护的空间离群点挖掘算法DPPASLOF(DistribuIcd Privacy Preserving Algorithm based on SLOF)。算法中利用空间数据的局部性,发挥各数据方的主动参与的能力,借助于空间索引技术和隐私保护协议以提高搜索能力和隐私保护能力。理论证明算法的安全性,计算的高效性和低通信代价。},
  language = {中文;},
  timestamp = {2016-07-19T03:13:11Z},
  urldate = {2016-07-19},
  school = {江苏大学},
  author = {薛, 安荣},
  year = {2008},
  keywords = {Attribute partitation,Data mining,ensemble learning,Local outlier factor,privacy preserving,pruning strategy,spatial index,Spatial outlier,剪枝策略,局部离群系数,属性划分,数据挖掘,空间离群点,空间索引,隐私保护,集成学习},
  file = {空间离群点挖掘技术的研究.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/空间离群点挖掘技术的研究.pdf:application/pdf}
}

@article{liu_outlier_2013,
  title = {Outlier Detection on Uncertain Data Based on Local Information},
  volume = {51},
  issn = {09507051},
  doi = {10.1016/j.knosys.2013.07.005},
  language = {en},
  timestamp = {2016-08-08T01:58:30Z},
  urldate = {2016-08-08},
  journal = {Knowledge-Based Systems},
  author = {Liu, Jing and Deng, HuiFang},
  month = oct,
  year = {2013},
  keywords = {Local information,outlier detection,Uncertain data,重要文献},
  pages = {60--71},
  file = {Outlier detection on uncertain data based on local information.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Outlier detection on uncertain data based on local information.pdf:application/pdf}
}

@misc{varoquaux_scipy-lecture-notes:_2015,
  title = {Scipy-Lecture-Notes: {{Release}} 2015.1 Beta},
  shorttitle = {Scipy-Lecture-Notes},
  abstract = {Tutorial material on the scientific Python ecosystem},
  timestamp = {2016-08-08T03:34:23Z},
  urldate = {2016-08-08},
  author = {Varoquaux, Gael and Lars and Gommers, Ralf and Vahtras, Olav and yasutomo57jp and kikocorreoso and reverland and Gouillart, Emmanuelle and Pedregosa, Fabian and Verdier, Olivier and Oller, Sergio and {de Buyl}, Pierre and Pinte, Didrik and Riehl, Maximilien and Gilli\ss{}en, Philip and Ingold, Gert-Ludwig and Uchida, Akihiro and {\c C}a{\u g}layan, Ozan and Cimrman, Robert and Virtanen, Pauli and Gieseke, Robert and {van der Walt}, Stefan and Turner, Wes and Pettiaux, Nicolas and Haenel, Valentin and aespaze and Rougier, Nicolas P. and Varoquaux, Nelle and J\k{e}drzejewski-Szmek, Zbigniew and Combelles, Christophe},
  month = sep,
  year = {2015},
  file = {scipy-lecture-notes - Release 2015.1 beta.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/scipy-lecture-notes - Release 2015.1 beta.pdf:application/pdf},
  doi = {10.5281/zenodo.31521}
}

@article{li_optimizing_2009,
  title = {Optimizing Construction Planning Schedules by Virtual Prototyping Enabled Resource Analysis},
  volume = {18},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2009.04.002},
  abstract = {The inherent uncertainty and complexity of construction work make construction planning a particularly difficult task for project managers due to the need to anticipate and visualize likely future events. Conventional computer-assisted technology can help but is often limited to the constructability issues involved. Virtual prototyping, however, offers an improved method through the visualization of construction activities by computer simulation \textemdash enabling a range of `what-if' questions to be asked and their implications on the total project to be investigated.

This paper describes the use of virtual prototyping to optimize construction planning schedules by analyzing resource allocation and planning with integrated construction models, resource models, construction planning schedules and site-layout plans. A real-life case study is presented that demonstrates the use of a virtual prototyping enabled resource analysis to reallocate space, logistic on access road and arrange tower cranes to achieve a 6-day floor construction cycle.},
  timestamp = {2016-08-09T06:17:13Z},
  number = {7},
  urldate = {2016-08-09},
  journal = {Automation in Construction},
  author = {Li, Heng and Chan, Neo and Huang, Ting and Guo, H. L. and Lu, Weisheng and Skitmore, Martin},
  year = {十一月 2009},
  keywords = {Construction planning schedule,Resource analysis,Space,Virtual prototyping},
  pages = {912--918},
  file = {Optimizing construction planning schedules by virtual prototyping enabled resource analysis.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Optimizing construction planning schedules by virtual prototyping enabled resource analysis.pdf:application/pdf}
}

@article{__2016,
  title = {{基于知识粒度的时间序列异常检测研究}},
  issn = {1673-629X},
  lccn = {61-1450/TP},
  abstract = {时间序列的异常检测多以相似性分析方法来处理,时间代价高昂。为减少异常检测的时间,文中围绕知识粒度方法进行研究与探讨。知识粒度在数据异常检测中应用广泛,但在时间序列的异常检测上应用较少。文中针对时间序列上下文相关异常(点)检测,提出利用知识粒度异常检测方法对于输入属性越多检测粒度越细的特性,来查找时间序列中的异常数据。实验证明,基于知识粒度的方法无需先验信息,在整个处理过程中无需事先分析历史数据,而是通过属性间的组合粒度来划分异常数据与正常数据,提高了异常检测的效率。知识粒度方法在不确定信息处理研究中的表现十分突出,文中将知识粒度在时间序列异常检测中进行应用尝试,为时间序列异常检测提供了一种新的思路。},
  language = {中文;},
  timestamp = {2016-08-24T18:57:26Z},
  number = {07},
  urldate = {2016-08-24},
  journal = {计算机技术与发展},
  author = {杨, 志勇 and 朱, 跃龙 and 万, 定生},
  year = {2016},
  keywords = {Anomaly detection,knowledge granularity,rough set,time series,异常检测,时间序列,知识粒度,粗糙集},
  pages = {51--54}
}

@article{__2016-1,
  title = {{具有趋势变异的非一致水文序列重现期计算研究}},
  issn = {1003-1243},
  lccn = {11-2241/TV},
  abstract = {气候变化和人类活动会导致水文序列的非一致性,而非一致水文序列的重现期计算方法并没有统一。本文对比了传统重现期、基准年重现期、基于事件发生时间期望(EWT)的重现期和通过序列成分分析法计算的重现期,以探讨具有趋势变异的非一致水文序列重现期计算方法。以渭河流域林家村站年径流量序列为例,构建时变参数概率模型,计算各类重现期相应的设计年径流量。结果表明,传统重现期计算方法用单一分布无法准确描述含有趋势变异的水文序列。在研究区年径流量呈现减小趋势的背景下,小径流量事件发生概率增大,但大重现期相应的设计年径流量并没有逐年减小。EWT重现期较基准重现期考虑了趋势变异的影响,而基准重现期计算简单。文中方法以期为非一致性水文序列频率分析提供依据。},
  language = {中文;},
  timestamp = {2016-08-24T18:57:41Z},
  number = {05},
  urldate = {2016-08-24},
  journal = {水力发电学报},
  author = {史, 黎翔 and 宋, 松柏},
  year = {2016},
  keywords = {hydrological frequency analysis,non-stationarity,return period,time-varying parameter model,时变参数模型,水文频率分析,重现期,非一致性},
  pages = {40--46}
}

@article{__2016-2,
  title = {{条件概率模型在非一致性水文序列频率计算中的应用}},
  issn = {1671-9387},
  lccn = {61-1390/S},
  abstract = {【目的】对条件概率模型在非一致性水文序列频率计算中的应用进行研究,为变化环境下的水文频率分析提供依据。【方法】基于条件概率模型,以渭河流域林家村、张家山和状头3个具有跳跃变异的水文站年平均流量系列为研究对象,选择两参数对数正态分布、三参数对数正态分布、Gumbel分布和PIII型分布4种分布模型,采用模拟退火粒子群算法进行参数估计,以效率系数R2等指标进行拟合优度评价并选取最佳模型,最后采用学生化残差分析所选模型的合理性。【结果】3个水文站序列的理论频率曲线与经验点据配合的效率系数均高于0.96,最佳模型的学生化残差均服从标准正态分布,表明基于条件概率模型的计算结果合理可靠。【结论】条件概率模型的物理意义明确、理论严密、拟合效果较优,是一种对具有跳跃变异的非一致性水文序列进行频率分析的有效途径。},
  language = {中文},
  timestamp = {2016-08-24T18:57:55Z},
  number = {08},
  urldate = {2016-08-24},
  journal = {西北农林科技大学学报(自然科学版)},
  author = {李, 伶杰 and 康, 艳 and 宋, 松柏 and 邓, 瑞强 and 金, 义蓉},
  year = {2016},
  keywords = {条件概率模型,水文序列,跳跃变异,非一致性,频率分析}
}

@misc{_time_2016,
  title = {Time Series},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {A time series is a series of data points listed (or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data. Examples of time series are heights of ocean tides, counts of sunspots, and the daily closing value of the Dow Jones Industrial Average.
Time series are very frequently plotted via line charts. Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, intelligent transport and trajectory forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and largely in any domain of applied science and engineering which involves temporal measurements.
Time series analysis comprises methods for analyzing time series data in order to extract meaningful statistics and other characteristics of the data. Time series forecasting is the use of a model to predict future values based on previously observed values. While regression analysis is often employed in such a way as to test theories that the current values of one or more independent time series affect the current value of another time series, this type of analysis of time series is not called "time series analysis", which focuses on comparing values of a single time series or multiple dependent time series at different points in time.
Time series data have a natural temporal ordering. This makes time series analysis distinct from cross-sectional studies, in which there is no natural ordering of the observations (e.g. explaining people's wages by reference to their respective education levels, where the individuals' data could be entered in any order). Time series analysis is also distinct from spatial data analysis where the observations typically relate to geographical locations (e.g. accounting for house prices by the location as well as the intrinsic characteristics of the houses). A stochastic model for a time series will generally reflect the fact that observations close together in time will be more closely related than observations further apart. In addition, time series models will often make use of the natural one-way ordering of time so that values for a given period will be expressed as deriving in some way from past values, rather than from future values (see time reversibility.)
Time series analysis can be applied to real-valued, continuous data, discrete numeric data, or discrete symbolic data (i.e. sequences of characters, such as letters and words in the English language).},
  language = {en},
  timestamp = {2016-08-24T19:01:46Z},
  urldate = {2016-08-24},
  journal = {Wikipedia, the free encyclopedia},
  month = aug,
  year = {2016},
  note = {Page Version ID: 732545965}
}

@misc{_statistical_2016,
  title = {Statistical Process Control},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {Statistical process control (SPC) is a method of quality control which uses statistical methods. SPC is applied in order to monitor and control a process. Monitoring and controlling the process ensures that it operates at its full potential. At its full potential, the process can make as much conforming product as possible with a minimum (if not an elimination) of waste (rework or scrap). SPC can be applied to any process where the "conforming product" (product meeting specifications) output can be measured. Key tools used in SPC include control charts; a focus on continuous improvement; and the design of experiments. An example of a process where SPC is applied is manufacturing lines.},
  language = {en},
  timestamp = {2016-08-28T08:26:17Z},
  urldate = {2016-08-28},
  journal = {Wikipedia, the free encyclopedia},
  month = aug,
  year = {2016},
  note = {Page Version ID: 735101913}
}

@article{branch_-network_2012,
  title = {In-Network Outlier Detection in Wireless Sensor Networks},
  volume = {34},
  issn = {0219-1377, 0219-3116},
  doi = {10.1007/s10115-011-0474-5},
  abstract = {To address the problem of unsupervised outlier detection in wireless sensor networks, we develop an approach that (1) is flexible with respect to the outlier definition, (2) computes the result in-network to reduce both bandwidth and energy consumption, (3) uses only single-hop communication, thus permitting very simple node failure detection and message reliability assurance mechanisms (e.g., carrier-sense), and (4) seamlessly accommodates dynamic updates to data. We examine performance by simulation, using real sensor data streams. Our results demonstrate that our approach is accurate and imposes reasonable communication and power consumption demands.},
  language = {en},
  timestamp = {2016-08-28T07:17:20Z},
  number = {1},
  urldate = {2016-08-28},
  journal = {Knowl Inf Syst},
  author = {Branch, Joel W. and Giannella, Chris and Szymanski, Boleslaw and Wolff, Ran and Kargupta, Hillol},
  month = jan,
  year = {2012},
  pages = {23--54},
  file = {In-network outlier detection in wireless sensor networks.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/In-network outlier detection in wireless sensor networks.pdf:application/pdf}
}

@inproceedings{janakiram_outlier_2006,
  title = {Outlier {{Detection}} in {{Wireless Sensor Networks}} Using {{Bayesian Belief Networks}}},
  doi = {10.1109/COMSWA.2006.1665221},
  abstract = {Data reliability is an important issue from the user's perspective, in the context of streamed data in wireless sensor networks (WSN). Reliability is affected by the harsh environmental conditions, interferences in wireless medium and usage of low quality sensors. Due to these conditions, the data generated by the sensors may get corrupted resulting in outliers and missing values. Deciding whether an observation is an outlier or not depends on the behavior of the neighbors' readings as well as the readings of the sensor itself. This can be done by capturing the spatio-temporal correlations that exists among the observations of the sensor nodes. By using naive Bayesian networks for classification, we can estimate whether an observation belongs to a class or not. If it falls beyond the range of the class, then it can be detected as an outlier. However naive Bayesian networks do not consider the conditional dependencies among the observations of sensor attributes. So, we propose an outlier detection scheme based on Bayesian belief networks, which captures the conditional dependencies among the observations of the attributes to detect the outliers in the sensor streamed data. Applicability of this scheme as a plug-in to the component oriented middleware for sensor networks (COMiS) of our early research work is also presented},
  timestamp = {2016-08-28T07:10:13Z},
  booktitle = {2006 1st {{International Conference}} on {{Communication Systems Software Middleware}}},
  author = {Janakiram, D. and Reddy, V. A. and Kumar, A. V. U. P.},
  year = {2006},
  keywords = {Bayesian belief network,Bayesian methods,belief networks,correlation methods,Data mining,data reliability,Intelligent networks,Intelligent sensors,Interference,Mechanical sensors,Middleware,object detection,outlier detection scheme,Sensor phenomena and characterization,spatio-temporal correlation,spatiotemporal phenomena,telecommunication network reliability,wireless sensor network,wireless sensor networks,WSN},
  pages = {1--6},
  file = {Outlier Detection in Wireless Sensor Networks using Bayesian Belief Networks.pdf:/home/daniel/CloudStation/Literature/Zotero/Storage/anomalydetection/Outlier Detection in Wireless Sensor Networks using Bayesian Belief Networks.pdf:application/pdf}
}


